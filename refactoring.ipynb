{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: imports & constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import music21 as m21\n",
    "import pretty_midi as pm\n",
    "import tempfile\n",
    "\n",
    "test_midi_folder = 'midiFiles/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: file to list of PCVs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.1 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursively_map_offset(midi_stream, only_note_name=True):\n",
    "    '''\n",
    "    This function will recursively walk through the Midi stream's elements, \n",
    "    and whenever it encounters a note, it will append its rhytmic \n",
    "    data to the pitch and then store the resulting data structure in an array.\n",
    "    If a music21 element of type chord is encountered, the chord is decomposed into all\n",
    "    notes it is composed by, and each of thoses notes are appended the \n",
    "    Returns the aforementionned array.\n",
    "    The rhytmic data is expressed as a tuple of the offset of the beginning of the note\n",
    "    and the offset of the end of the note.\n",
    "    \n",
    "    All temporal informations from MIDI events parsed by the music21 library are encoded\n",
    "    as unit of quarter notes count, regardless of the bpm or the time signature.\n",
    "    \n",
    "    Params: \n",
    "    midi stream: the MIDI stream containing all the relevant infos\n",
    "    flatten: Boolean, indicating whether or not the chords elements \n",
    "            need to be flattened into singles notes.\n",
    "    only_note_name: Boolean, indicating whether the notes need to be \n",
    "                    converted from music21 object with octave indication\n",
    "                    to only a string indicating the pitch.\n",
    "    '''\n",
    "    \n",
    "    res = []\n",
    "    for elem in midi_stream.recurse():\n",
    "        if isinstance(elem, m21.note.Note):\n",
    "            start_offset = elem.getOffsetInHierarchy(midi_stream)\n",
    "            res.append((elem.name if only_note_name else elem, (start_offset, start_offset+elem.duration.quarterLength)))\n",
    "        elif isinstance(elem, m21.chord.Chord):\n",
    "            start_offset = elem.getOffsetInHierarchy(midi_stream)\n",
    "            res += list(map(lambda r: (r.name if only_note_name else r , (start_offset, start_offset+elem.duration.quarterLength)), elem.pitches))\n",
    "    return res\n",
    "\n",
    "\n",
    "def remove_drums_from_midi_file(midi_filename):\n",
    "    '''\n",
    "    Takes care of removing drum tracks from a midi filename.\n",
    "    Work only if the MIDI file has metadata clearly indicating channels that are\n",
    "    percussive. Does not remove channels of percussive instruments that are pitched\n",
    "    (like the glockenspiel for instance).  \n",
    "    \n",
    "    Param: \n",
    "    \n",
    "    returns:\n",
    "    The (temporary) filepath of the midi file generated without the drum channel.\n",
    "    \n",
    "    '''\n",
    "    sound = pm.PrettyMIDI(midi_path)\n",
    "    \n",
    "    #getting\n",
    "    drum_instruments_index = [idx for idx, instrument in enumerate(sound.instruments) if instrument.is_drum]\n",
    "    for i in sorted(drum_instruments_index, reverse=True):\n",
    "        del sound.instruments[i]\n",
    "\n",
    "    folder = tempfile.TemporaryDirectory()\n",
    "    temp_midi_filepath = folder.name+'tmp.mid'\n",
    "    sound.write(temp_midi_filepath)\n",
    "    \n",
    "    return temp_midi_filepath\n",
    "\n",
    "\n",
    "def only_keep_pitches_in_boundaries(pitch_offset_list, beat1_offset, beat2_offset): \n",
    "    return list(filter(lambda n: n[1][1] >= beat1_offset and n[1][0] <= beat2_offset, pitch_offset_list))\n",
    "\n",
    "\n",
    "def slice_according_to_beat(pitch_offset_list, beat1_offset, beat2_offset):\n",
    "    #the beat offset must be expressed as relation of quarter note. \n",
    "    #Taken are all beat which at least END AFTER the beat1, and START BEFORE the beat2\n",
    "    res = []\n",
    "    if beat1_offset >= beat2_offset:\n",
    "        return res\n",
    "    for n in only_keep_pitches_in_boundaries(pitch_offset_list, beat1_offset, beat2_offset):\n",
    "        start_b = n[1][0]\n",
    "        end_b = n[1][1]\n",
    "        \n",
    "        res_n = None\n",
    "        if start_b >= beat1_offset:\n",
    "            if end_b > beat2_offset:\n",
    "                res_n = (n[0], (start_b, beat2_offset))\n",
    "            else:\n",
    "                res_n = (n[0], (start_b, end_b))\n",
    "        elif end_b <= beat2_offset:\n",
    "            #if start_b < beat1_offset: #of course we are in this case since the first if was not triggered.\n",
    "            res_n = (n[0], (beat1_offset, end_b))\n",
    "        else:\n",
    "            #we are thus in the case the start and end time of the note overshoot the boundaries.\n",
    "            res_n = (n[0], (beat1_offset, beat2_offset))\n",
    "        #normally inconsistent results should not happen, but it is possible to have a note with duration equals to 0. This line below prevents that and thus keep the things concise.\n",
    "        if res_n[1][0] < res_n[1][1]:\n",
    "            res.append(res_n)\n",
    "    return res\n",
    "\n",
    "def sum_into_pitch_class_vector(pitch_offset_list, start_beat, end_beat):\n",
    "    pitch_class_offset = lambda t: pitch_index_dict[normalize_notation_dict[t[0]]]\n",
    "    pitch_class_vec = np.zeros(12)\n",
    "    for tup in pitch_offset_list:\n",
    "        #we need to be sure we don't take into account the part of the note that exceed the window's size.\n",
    "        min_beat = max(start_beat, tup[1][0])\n",
    "        max_beat = min(end_beat, tup[1][1])\n",
    "        pitch_weight = max_beat - min_beat\n",
    "        pitch_class_vec[pitch_class_offset(tup)] += pitch_weight\n",
    "    return pitch_class_vec\n",
    "\n",
    "\n",
    "\n",
    "def pitch_class_set_vector_from_pitch_offset_list(pitch_offset_array, chunk_number=0.0): #the analysis window size (aw_size) is expressed in terms of number of quarter.\n",
    "    max_beat = get_max_beat(pitch_offset_array)\n",
    "    chunk_number = chunk_number if chunk_number > 0. else max_beat\n",
    "    aw_size = float(max_beat)/chunk_number\n",
    "    res_vector = np.full((chunk_number, 12), 0.0, np.float32)\n",
    "\n",
    "    for b in range(math.ceil(max_beat/aw_size)):\n",
    "        start_beat = b*aw_size\n",
    "        stop_beat = (b+1)*aw_size\n",
    "        analysis_window = slice_according_to_beat(pitch_offset_array, start_beat, stop_beat)\n",
    "        pitch_class_vec = sum_into_pitch_class_vector(analysis_window, start_beat, stop_beat)\n",
    "        res_vector[b] = pitch_class_vec\n",
    "    \n",
    "    return res_vector\n",
    "\n",
    "\n",
    "def produce_pitch_class_matrix_from_filename(filename, remove_percussions = True, aw_size = 0.5):\n",
    "    '''\n",
    "    TODO comments\n",
    "    '''\n",
    "    if filename.endswith('.mid') or filename.endswith('.midi'):\n",
    "        midi_filename = remove_drums_from_midi_file(filename) if remove_percussions else filename\n",
    "        pitch_offset_list = recursively_map_offset(midi_filename)\n",
    "        \n",
    "    elif filename.endswith('.wav'):\n",
    "        return None\n",
    "        #TODO: add code there.\n",
    "    else:\n",
    "        raise Exception('The file should be in MIDI or WAV format')\n",
    "        \n",
    "    return recursively_map_offset(midi_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_path = test_midi_folder+'NCandP.mid'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
