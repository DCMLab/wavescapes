{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: imports & constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import music21 as m21\n",
    "import pretty_midi as pm\n",
    "import tempfile\n",
    "import math\n",
    "\n",
    "test_midi_folder = 'midiFiles/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: file to list of PCVs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.1 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "twelve_tones_vector_name = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#','A', 'A#', 'B']\n",
    "\n",
    "altered_notation_dict = {\n",
    "    'B#' : 'C',\n",
    "    'D-' : 'C#',\n",
    "    'E-' : 'D#',\n",
    "    'F-' : 'E',\n",
    "    'E#' : 'F',\n",
    "    'G-' : 'F#',\n",
    "    'A-' : 'G#',\n",
    "    'B-' : 'A#',\n",
    "    'C-' : 'B'\n",
    "} \n",
    "\n",
    "pitch_pitch_dict = {x: x for x in twelve_tones_vector_name}\n",
    "\n",
    "#In the end we want each string to match an index between 0 and 11, so it fits inside a 12-d vector.\n",
    "pitch_index_dict = {twelve_tones_vector_name[i]:i for i in range(len(twelve_tones_vector_name))}\n",
    "\n",
    "#So any pitch name given to this dict will be mapped to its cannonical form defined in 'twelve_tones_vector_name'\n",
    "normalize_notation_dict = dict(altered_notation_dict,  **pitch_pitch_dict)\n",
    "\n",
    "def recursively_map_offset(filename, only_note_name=True):\n",
    "    '''\n",
    "    This function will recursively walk through the Midi stream's elements, \n",
    "    and whenever it encounters a note, it will append its rhytmic \n",
    "    data to the pitch and then store the resulting data structure in an array.\n",
    "    If a music21 element of type chord is encountered, the chord is decomposed into all\n",
    "    notes it is composed by, and each of thoses notes are appended the \n",
    "    Returns the aforementionned array.\n",
    "    The rhytmic data is expressed as a tuple of the offset of the beginning of the note\n",
    "    and the offset of the end of the note.\n",
    "    \n",
    "    All temporal informations from MIDI events parsed by the music21 library are encoded\n",
    "    as unit of quarter notes count, regardless of the bpm or the time signature.\n",
    "    \n",
    "    Params: \n",
    "    midi stream: the MIDI stream containing all the relevant infos\n",
    "    flatten: Boolean, indicating whether or not the chords elements \n",
    "            need to be flattened into singles notes.\n",
    "    only_note_name: Boolean, indicating whether the notes need to be \n",
    "                    converted from music21 object with octave indication\n",
    "                    to only a string indicating the pitch.\n",
    "    '''\n",
    "    midi_stream = m21.converter.parse(filename)\n",
    "    res = []\n",
    "    for elem in midi_stream.recurse():\n",
    "        if isinstance(elem, m21.note.Note):\n",
    "            start_offset = elem.getOffsetInHierarchy(midi_stream)\n",
    "            res.append((elem.name if only_note_name else elem, (start_offset, start_offset+elem.duration.quarterLength)))\n",
    "        elif isinstance(elem, m21.chord.Chord):\n",
    "            start_offset = elem.getOffsetInHierarchy(midi_stream)\n",
    "            res += list(map(lambda r: (r.name if only_note_name else r , (start_offset, start_offset+elem.duration.quarterLength)), elem.pitches))\n",
    "    return res\n",
    "\n",
    "\n",
    "def remove_drums_from_midi_file(midi_filename):\n",
    "    '''\n",
    "    Takes care of removing drum tracks from a midi filename.\n",
    "    Work only if the MIDI file has metadata clearly indicating channels that are\n",
    "    percussive. Does not remove channels of percussive instruments that are pitched\n",
    "    (like the glockenspiel for instance).  \n",
    "    \n",
    "    Param: \n",
    "    \n",
    "    returns:\n",
    "    The (temporary) filepath of the midi file generated without the drum channel.\n",
    "    \n",
    "    '''\n",
    "    sound = pm.PrettyMIDI(midi_filename)\n",
    "    \n",
    "    #getting\n",
    "    drum_instruments_index = [idx for idx, instrument in enumerate(sound.instruments) if instrument.is_drum]\n",
    "    for i in sorted(drum_instruments_index, reverse=True):\n",
    "        del sound.instruments[i]\n",
    "\n",
    "    folder = tempfile.TemporaryDirectory()\n",
    "    temp_midi_filepath = folder.name+'tmp.mid'\n",
    "    sound.write(temp_midi_filepath)\n",
    "    \n",
    "    return temp_midi_filepath\n",
    "\n",
    "\n",
    "def only_keep_pitches_in_boundaries(pitch_offset_list, beat1_offset, beat2_offset): \n",
    "    return list(filter(lambda n: n[1][1] >= beat1_offset and n[1][0] <= beat2_offset, pitch_offset_list))\n",
    "\n",
    "\n",
    "def slice_according_to_beat(pitch_offset_list, beat1_offset, beat2_offset):\n",
    "    #the beat offset must be expressed as relation of quarter note. \n",
    "    #Taken are all beat which at least END AFTER the beat1, and START BEFORE the beat2\n",
    "    res = []\n",
    "    if beat1_offset >= beat2_offset:\n",
    "        return res\n",
    "    for n in only_keep_pitches_in_boundaries(pitch_offset_list, beat1_offset, beat2_offset):\n",
    "        start_b = n[1][0]\n",
    "        end_b = n[1][1]\n",
    "        \n",
    "        res_n = None\n",
    "        if start_b >= beat1_offset:\n",
    "            if end_b > beat2_offset:\n",
    "                res_n = (n[0], (start_b, beat2_offset))\n",
    "            else:\n",
    "                res_n = (n[0], (start_b, end_b))\n",
    "        elif end_b <= beat2_offset:\n",
    "            #if start_b < beat1_offset: #of course we are in this case since the first if was not triggered.\n",
    "            res_n = (n[0], (beat1_offset, end_b))\n",
    "        else:\n",
    "            #we are thus in the case the start and end time of the note overshoot the boundaries.\n",
    "            res_n = (n[0], (beat1_offset, beat2_offset))\n",
    "        #normally inconsistent results should not happen, but it is possible to have a note with duration equals to 0. This line below prevents that and thus keep the things concise.\n",
    "        if res_n[1][0] < res_n[1][1]:\n",
    "            res.append(res_n)\n",
    "    return res\n",
    "\n",
    "def sum_into_pitch_class_vector(pitch_offset_list, start_beat, end_beat):\n",
    "    pitch_class_offset = lambda t: pitch_index_dict[normalize_notation_dict[t[0]]]\n",
    "    pitch_class_vec = np.zeros(12)\n",
    "    for tup in pitch_offset_list:\n",
    "        #we need to be sure we don't take into account the part of the note that exceed the window's size.\n",
    "        min_beat = max(start_beat, tup[1][0])\n",
    "        max_beat = min(end_beat, tup[1][1])\n",
    "        pitch_weight = max_beat - min_beat\n",
    "        pitch_class_vec[pitch_class_offset(tup)] += pitch_weight\n",
    "    return pitch_class_vec\n",
    "\n",
    "\n",
    "def pitch_class_set_vector_from_pitch_offset_list(pitch_offset_array, aw_size=0.5): #the analysis window size (aw_size) is expressed in terms of number of quarter.\n",
    "    \n",
    "    def get_max_beat(pitch_offset_list):\n",
    "        return math.ceil(max(list(map(lambda r: r[1][1], pitch_offset_list))))\n",
    "    \n",
    "    max_beat = get_max_beat(pitch_offset_array)\n",
    "    \n",
    "    if aw_size <= max_beat/2:\n",
    "        chunk_number = math.ceil(max_beat/aw_size)\n",
    "    else:\n",
    "        raise Exception('The analysis window\\'s size should not exceed half the duration of the musical piece.')\n",
    "    \n",
    "    res_vector = np.full((chunk_number, 12), 0.0, np.float64)\n",
    "\n",
    "    for b in range(chunk_number):\n",
    "        start_beat = b*aw_size\n",
    "        stop_beat = (b+1)*aw_size\n",
    "        analysis_windows = slice_according_to_beat(pitch_offset_array, start_beat, stop_beat)\n",
    "        pitch_class_vec = sum_into_pitch_class_vector(analysis_windows, start_beat, stop_beat)\n",
    "        res_vector[b] = pitch_class_vec\n",
    "    \n",
    "    return res_vector\n",
    "\n",
    "\n",
    "def produce_pitch_class_matrix_from_filename(filename, remove_percussions = True, aw_size = 0.5):\n",
    "    '''\n",
    "    TODO comments\n",
    "    '''\n",
    "    if filename.endswith('.mid') or filename.endswith('.midi'):\n",
    "        midi_filename = remove_drums_from_midi_file(filename) if remove_percussions else filename\n",
    "        pitch_offset_list = recursively_map_offset(midi_filename)\n",
    "        return pitch_class_set_vector_from_pitch_offset_list(pitch_offset_list, aw_size)\n",
    "    elif filename.endswith('.wav'):\n",
    "        return None\n",
    "        #TODO: add code there.\n",
    "    else:\n",
    "        raise Exception('The file should be in MIDI or WAV format')\n",
    "        \n",
    "    return recursively_map_offset(midi_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2 tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[36.  ,  1.  , 32.75,  0.  , 24.5 , 20.5 ,  2.  , 24.  ,  3.5 ,\n",
       "        18.  ,  3.5 , 18.  ],\n",
       "       [53.5 ,  0.  , 19.5 ,  4.5 , 19.75, 20.75,  5.  , 52.5 ,  4.  ,\n",
       "         4.  ,  2.  ,  9.25]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Tests on a MIDI transcription of Bach's Prelude\n",
    "bach_prelude_midi = test_midi_folder + '210606-Prelude_No._1_BWV_846_in_C_Major.mid'\n",
    "\n",
    "#### MAX BEAT TEST\n",
    "BACH_PRELUDE_MAX_BEAT = 35 * 4\n",
    "bp_po_list = recursively_map_offset(bach_prelude_midi)\n",
    "assert(BACH_PRELUDE_MAX_BEAT == get_max_beat(bp_po_list))\n",
    "\n",
    "#### DEFAULT AW SIZE TEST\n",
    "bp_pcm = produce_pitch_class_matrix_from_filename(bach_prelude_midi)\n",
    "assert(np.shape(bp_pcm)[0] == 2*BACH_PRELUDE_MAX_BEAT)\n",
    "\n",
    "#### AW SIZE = 1 TEST\n",
    "\n",
    "bp_pcm_aw1 = produce_pitch_class_matrix_from_filename(bach_prelude_midi, aw_size=1)\n",
    "assert(np.shape(bp_pcm_aw1)[0] == BACH_PRELUDE_MAX_BEAT)\n",
    "\n",
    "#### AW_SIZE = MAX_BEAT/2 \n",
    "\n",
    "bp_pcm_aw_half = produce_pitch_class_matrix_from_filename(bach_prelude_midi, aw_size=BACH_PRELUDE_MAX_BEAT/2)\n",
    "assert(np.shape(bp_pcm_aw_half)[0] == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Apply DFT and Generate UTM\n",
    "\n",
    "### Part 2.1 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dft_utm_from_one_row(res):\n",
    "    pcv_nmb = np.shape(res)[0]\n",
    "    for i in range(1, pcv_nmb):\n",
    "        for j in range(0, pcv_nmb-i):\n",
    "            res[i][i+j] = res[0][i+j] + res[i-1][i+j-1]\n",
    "    return res\n",
    "\n",
    "def apply_dft_to_pitch_class_matrix(pc_mat, build_utm = True):\n",
    "    pcv_nmb, pc_nmb = np.shape(pc_mat)\n",
    "    #+1 to hold room for the 0th coefficient\n",
    "    coeff_nmb = int(pc_nmb/2)+1\n",
    "    res_dimensions = (pcv_nmb, coeff_nmb)\n",
    "    res = np.full(res_dimensions, (0. + 0.j), np.complex128)\n",
    "\n",
    "    for i in pcv_nmb:\n",
    "        res[i] = np.fft.fft(pc_mat[i])[:coeff_nmb] #coeff 7 to 11 are uninteresting (conjugates of coeff 6 to 1).\n",
    "    \n",
    "    if build_utm:\n",
    "        new_res = np.full((pcv_nmb, pcv_nmb, coeff_nmb), (0. + 0.j), np.complex128)\n",
    "        new_res[0] = res \n",
    "        res = build_dft_utm_from_one_row(new_res)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2 Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
